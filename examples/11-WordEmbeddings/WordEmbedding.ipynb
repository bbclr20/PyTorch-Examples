{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Embeddings\n",
    "\n",
    "Word embeddings are a representation of the ***semantics*** of a word, efficiently encoding semantic information that might be relevant to the task at hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f00f8012dd0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "torch.manual_seed(64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding(2, 5)\n"
     ]
    }
   ],
   "source": [
    "word_to_idx = {\"hello\": 0, \"world\": 1}\n",
    "embeds = nn.Embedding(2, 5) # 2 words in vocab, 5 dimensional embeddings\n",
    "\n",
    "print(embeds) # index i stores in the iâ€™th row of the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello_embed:  tensor([[-0.8159,  0.6431,  0.1268, -0.8538,  0.7698]],\n",
      "       grad_fn=<EmbeddingBackward>)\n",
      "world_embed:  tensor([[-0.1140, -0.4436, -1.9793,  1.1040,  0.1535]],\n",
      "       grad_fn=<EmbeddingBackward>)\n"
     ]
    }
   ],
   "source": [
    "lookup_tensor = torch.tensor([word_to_idx[\"hello\"]], dtype=torch.long)\n",
    "hello_embed = embeds(lookup_tensor)\n",
    "print(\"hello_embed: \", hello_embed)\n",
    "\n",
    "lookup_tensor = torch.tensor([word_to_idx[\"world\"]], dtype=torch.long)\n",
    "world_embed = embeds(lookup_tensor)\n",
    "print(\"world_embed: \", world_embed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An Example: N-Gram Language Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONTEXT_SIZE = 2\n",
    "EMBEDDING_DIM = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['When', 'forty', 'winters', 'shall', 'besiege', 'thy', 'brow,', 'And', 'dig', 'deep', 'trenches', 'in', 'thy', \"beauty's\", 'field,', 'Thy', \"youth's\", 'proud', 'livery', 'so', 'gazed', 'on', 'now,', 'Will', 'be', 'a', \"totter'd\", 'weed', 'of', 'small', 'worth', 'held:', 'Then', 'being', 'asked,', 'where', 'all', 'thy', 'beauty', 'lies,', 'Where', 'all', 'the', 'treasure', 'of', 'thy', 'lusty', 'days;', 'To', 'say,', 'within', 'thine', 'own', 'deep', 'sunken', 'eyes,', 'Were', 'an', 'all-eating', 'shame,', 'and', 'thriftless', 'praise.', 'How', 'much', 'more', 'praise', \"deserv'd\", 'thy', \"beauty's\", 'use,', 'If', 'thou', 'couldst', 'answer', \"'This\", 'fair', 'child', 'of', 'mine', 'Shall', 'sum', 'my', 'count,', 'and', 'make', 'my', 'old', \"excuse,'\", 'Proving', 'his', 'beauty', 'by', 'succession', 'thine!', 'This', 'were', 'to', 'be', 'new', 'made', 'when', 'thou', 'art', 'old,', 'And', 'see', 'thy', 'blood', 'warm', 'when', 'thou', \"feel'st\", 'it', 'cold.']\n"
     ]
    }
   ],
   "source": [
    "test_sentence = \"\"\"\n",
    "When forty winters shall besiege thy brow,\n",
    "And dig deep trenches in thy beauty's field,\n",
    "Thy youth's proud livery so gazed on now,\n",
    "Will be a totter'd weed of small worth held:\n",
    "Then being asked, where all thy beauty lies,\n",
    "Where all the treasure of thy lusty days;\n",
    "To say, within thine own deep sunken eyes,\n",
    "Were an all-eating shame, and thriftless praise.\n",
    "How much more praise deserv'd thy beauty's use,\n",
    "If thou couldst answer 'This fair child of mine\n",
    "Shall sum my count, and make my old excuse,'\n",
    "Proving his beauty by succession thine!\n",
    "This were to be new made when thou art old,\n",
    "And see thy blood warm when thou feel'st it cold.\n",
    "\"\"\".split()\n",
    "\n",
    "print(test_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'int'>, {'see': 1, 'This': 1, 'If': 1, 'small': 1, 'Then': 1, 'besiege': 1, 'praise': 1, 'gazed': 1, 'so': 1, \"totter'd\": 1, 'art': 1, 'made': 1, 'new': 1, 'say,': 1, \"deserv'd\": 1, 'praise.': 1, 'all-eating': 1, 'thine': 1, 'Where': 1, 'thy': 6, 'weed': 1, \"feel'st\": 1, 'blood': 1, 'treasure': 1, 'it': 1, 'proud': 1, 'more': 1, 'days;': 1, 'old,': 1, 'fair': 1, 'cold.': 1, 'shame,': 1, 'to': 1, 'when': 2, 'be': 2, 'held:': 1, 'dig': 1, \"'This\": 1, 'shall': 1, 'a': 1, 'within': 1, 'count,': 1, 'Thy': 1, \"beauty's\": 2, 'the': 1, 'thriftless': 1, 'own': 1, 'mine': 1, 'And': 2, 'Shall': 1, 'warm': 1, 'use,': 1, 'trenches': 1, 'brow,': 1, 'Proving': 1, 'my': 2, 'an': 1, 'where': 1, 'couldst': 1, 'make': 1, 'answer': 1, \"youth's\": 1, 'When': 1, 'sum': 1, 'eyes,': 1, 'beauty': 2, 'forty': 1, 'succession': 1, 'How': 1, 'field,': 1, 'Will': 1, 'worth': 1, 'were': 1, \"excuse,'\": 1, 'lies,': 1, 'his': 1, 'deep': 2, 'asked,': 1, 'lusty': 1, 'Were': 1, 'in': 1, 'livery': 1, 'winters': 1, 'sunken': 1, 'now,': 1, 'child': 1, 'being': 1, 'thou': 3, 'on': 1, 'by': 1, 'of': 3, 'and': 2, 'thine!': 1, 'all': 2, 'old': 1, 'much': 1, 'To': 1})\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "freq = defaultdict(int)\n",
    "for w in test_sentence:\n",
    "  freq[w] += 1\n",
    "print(freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(['When', 'forty'], 'winters'), (['forty', 'winters'], 'shall'), (['winters', 'shall'], 'besiege')]\n"
     ]
    }
   ],
   "source": [
    "# trigram: ([ word_i-2, word_i-1 ], target word)\n",
    "trigrams = [\n",
    "    ([test_sentence[i], test_sentence[i + 1]], test_sentence[i + 2])\n",
    "    for i in range(len(test_sentence) - 2)\n",
    "]\n",
    "\n",
    "# print the first 3\n",
    "print(trigrams[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove duplicate and build index\n",
    "vocab = set(test_sentence)\n",
    "word_to_ix = {word: i for i, word in enumerate(vocab)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NGramLanguageModeler(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size, embedding_dim, context_size):\n",
    "        super(NGramLanguageModeler, self).__init__()   \n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.linear1 = nn.Linear(context_size * embedding_dim, 128)\n",
    "        self.linear2 = nn.Linear(128, vocab_size)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        embeds = self.embeddings(inputs).view((1, -1))\n",
    "        out = F.relu(self.linear1(embeds))\n",
    "        out = self.linear2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.CrossEntropyLoss()\n",
    "model = NGramLanguageModeler(len(vocab), EMBEDDING_DIM, CONTEXT_SIZE)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "winter:  tensor([[ 0.1541,  1.4181,  0.9295,  1.0273, -0.1369, -1.2427,  0.0297,  0.6228,\n",
      "         -0.3465,  0.2267]], grad_fn=<EmbeddingBackward>)\n",
      "tensor([-0.1794], grad_fn=<DivBackward0>)\n",
      "tensor([0.1908], grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# just for fun\n",
    "winter_lookup = torch.tensor([word_to_ix[\"winters\"]], dtype=torch.long)\n",
    "warm_lookup = torch.tensor([word_to_ix[\"warm\"]], dtype=torch.long)\n",
    "thy_lookup = torch.tensor([word_to_ix[\"thy\"]], dtype=torch.long)\n",
    "\n",
    "winter = model.embeddings(winter_lookup)\n",
    "warm = model.embeddings(warm_lookup)\n",
    "thy = model.embeddings(thy_lookup)\n",
    "\n",
    "print(\"winter: \", winter)\n",
    "print(F.cosine_similarity(winter, warm))\n",
    "print(F.cosine_similarity(winter, thy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  10, total_loss: 4.4161\n",
      "Epoch:  20, total_loss: 4.2153\n",
      "Epoch:  30, total_loss: 4.0180\n",
      "Epoch:  40, total_loss: 3.8211\n",
      "Epoch:  50, total_loss: 3.6217\n",
      "Epoch:  60, total_loss: 3.4167\n",
      "Epoch:  70, total_loss: 3.2040\n",
      "Epoch:  80, total_loss: 2.9834\n",
      "Epoch:  90, total_loss: 2.7561\n",
      "Epoch: 100, total_loss: 2.5246\n",
      "Epoch: 110, total_loss: 2.2922\n",
      "Epoch: 120, total_loss: 2.0627\n",
      "Epoch: 130, total_loss: 1.8403\n",
      "Epoch: 140, total_loss: 1.6282\n",
      "Epoch: 150, total_loss: 1.4293\n",
      "Epoch: 160, total_loss: 1.2465\n",
      "Epoch: 170, total_loss: 1.0816\n",
      "Epoch: 180, total_loss: 0.9355\n",
      "Epoch: 190, total_loss: 0.8086\n",
      "Epoch: 200, total_loss: 0.6998\n",
      "Epoch: 210, total_loss: 0.6077\n",
      "Epoch: 220, total_loss: 0.5304\n",
      "Epoch: 230, total_loss: 0.4657\n",
      "Epoch: 240, total_loss: 0.4119\n",
      "Epoch: 250, total_loss: 0.3670\n",
      "Epoch: 260, total_loss: 0.3294\n",
      "Epoch: 270, total_loss: 0.2978\n",
      "Epoch: 280, total_loss: 0.2711\n",
      "Epoch: 290, total_loss: 0.2484\n",
      "Epoch: 300, total_loss: 0.2289\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 301):\n",
    "    total_loss = 0\n",
    "    for context, target in trigrams:\n",
    "        context_idxs = torch.tensor([word_to_ix[w] for w in context], dtype=torch.long)\n",
    "        model.zero_grad()\n",
    "\n",
    "        out = model(context_idxs)\n",
    "        label = torch.tensor([word_to_ix[target]], dtype=torch.long)\n",
    "        loss = loss_function(out, label)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    if epoch%10 == 0:\n",
    "        total_loss = total_loss/len(trigrams)\n",
    "        print(\"Epoch: {:3d}, total_loss: {:3.4f}\".format(epoch, total_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "winter:  tensor([[ 0.1268,  1.4652,  0.9505,  1.0286, -0.1670, -1.2583,  0.0223,  0.6076,\n",
      "         -0.3706,  0.2573]], grad_fn=<EmbeddingBackward>)\n",
      "tensor([-0.1797], grad_fn=<DivBackward0>)\n",
      "tensor([0.1887], grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# just for fun\n",
    "winter_lookup = torch.tensor([word_to_ix[\"winters\"]], dtype=torch.long)\n",
    "warm_lookup = torch.tensor([word_to_ix[\"warm\"]], dtype=torch.long)\n",
    "thy_lookup = torch.tensor([word_to_ix[\"thy\"]], dtype=torch.long)\n",
    "\n",
    "winter = model.embeddings(winter_lookup)\n",
    "warm = model.embeddings(warm_lookup)\n",
    "thy = model.embeddings(thy_lookup)\n",
    "\n",
    "print(\"winter: \", winter)\n",
    "print(F.cosine_similarity(winter, warm))\n",
    "print(F.cosine_similarity(winter, thy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Continuous Bag-of-Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONTEXT_SIZE = 2  # 2 words to the left, 2 to the right\n",
    "raw_text = \"\"\"\n",
    "We are about to study the idea of a computational process.\n",
    "Computational processes are abstract beings that inhabit computers.\n",
    "As they evolve, processes manipulate other abstract things called data.\n",
    "The evolution of a process is directed by a pattern of rules\n",
    "called a program. People create programs to direct processes. In effect,\n",
    "we conjure the spirits of the computer with our spells.\n",
    "\"\"\".split()\n",
    "\n",
    "# By deriving a set from `raw_text`, we deduplicate the array\n",
    "vocab = set(raw_text)\n",
    "vocab_size = len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(['We', 'are', 'to', 'study'], 'about'), (['are', 'about', 'study', 'the'], 'to'), (['about', 'to', 'the', 'idea'], 'study'), (['to', 'study', 'idea', 'of'], 'the'), (['study', 'the', 'of', 'a'], 'idea')]\n"
     ]
    }
   ],
   "source": [
    "word_to_ix = {word: i for i, word in enumerate(vocab)}\n",
    "data = []\n",
    "for i in range(2, len(raw_text) - 2):\n",
    "    context = [raw_text[i - 2], raw_text[i - 1],\n",
    "               raw_text[i + 1], raw_text[i + 2]]\n",
    "    target = raw_text[i]\n",
    "    data.append((context, target))\n",
    "print(data[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CBOW(nn.Module):\n",
    "\n",
    "    \n",
    "    def __init__(self, vocab_size, embedding_dim):\n",
    "        super(CBOW, self).__init__()   \n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.linear1 = nn.Linear(embedding_dim, vocab_size)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        embeds = self.embeddings(inputs)\n",
    "        embeds = torch.sum(embeds, dim=0).view((1, -1))\n",
    "        out = self.linear1(embeds)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.CrossEntropyLoss()\n",
    "model = CBOW(len(vocab), EMBEDDING_DIM)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([42, 48,  8, 13])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def make_context_vector(context, word_to_ix):\n",
    "    idxs = [word_to_ix[w] for w in context]\n",
    "    return torch.tensor(idxs, dtype=torch.long)\n",
    "\n",
    "\n",
    "make_context_vector(data[0][0], word_to_ix)  # example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  10, total_loss: 2.1359\n",
      "Epoch:  20, total_loss: 1.9306\n",
      "Epoch:  30, total_loss: 1.7595\n",
      "Epoch:  40, total_loss: 1.6148\n",
      "Epoch:  50, total_loss: 1.4905\n",
      "Epoch:  60, total_loss: 1.3824\n",
      "Epoch:  70, total_loss: 1.2876\n",
      "Epoch:  80, total_loss: 1.2036\n",
      "Epoch:  90, total_loss: 1.1286\n",
      "Epoch: 100, total_loss: 1.0611\n",
      "Epoch: 110, total_loss: 1.0000\n",
      "Epoch: 120, total_loss: 0.9443\n",
      "Epoch: 130, total_loss: 0.8934\n",
      "Epoch: 140, total_loss: 0.8466\n",
      "Epoch: 150, total_loss: 0.8034\n",
      "Epoch: 160, total_loss: 0.7634\n",
      "Epoch: 170, total_loss: 0.7262\n",
      "Epoch: 180, total_loss: 0.6915\n",
      "Epoch: 190, total_loss: 0.6591\n",
      "Epoch: 200, total_loss: 0.6287\n",
      "Epoch: 210, total_loss: 0.6001\n",
      "Epoch: 220, total_loss: 0.5733\n",
      "Epoch: 230, total_loss: 0.5480\n",
      "Epoch: 240, total_loss: 0.5241\n",
      "Epoch: 250, total_loss: 0.5016\n",
      "Epoch: 260, total_loss: 0.4803\n",
      "Epoch: 270, total_loss: 0.4601\n",
      "Epoch: 280, total_loss: 0.4411\n",
      "Epoch: 290, total_loss: 0.4230\n",
      "Epoch: 300, total_loss: 0.4059\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 301):\n",
    "    total_loss = 0\n",
    "    for context, target in data:\n",
    "        context_idxs = make_context_vector(context, word_to_ix)\n",
    "        model.zero_grad()\n",
    "        \n",
    "        out = model(context_idxs)\n",
    "        label = torch.tensor([word_to_ix[target]], dtype=torch.long)\n",
    "        loss = loss_function(out, label)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    if epoch%10 == 0:\n",
    "        total_loss = total_loss/len(trigrams)\n",
    "        print(\"Epoch: {:3d}, total_loss: {:3.4f}\".format(epoch, total_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
